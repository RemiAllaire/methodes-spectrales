# üìò Chapitre 1 ‚Äì Introduction

## üéØ Objectifs
- R√©sumer la mati√®re
- Recr√©er quelques exemples

## üìù Notes
Soit $u(x)$ la solution d'une √©quation diff√©rentielle, on assume qu'elle peut √™tre repr√©sent√©e par une somme de fonction de bases $\phi_{n}(x)$  tel que:
$$
u(x) \approx u_{N}(x) = \sum_{N=0}^{N}a_{n}\phi_{n}(x)
$$
Soit $L$ l'op√©rateur diff√©rentiel de sorte que
$$
Lu = f(x)
$$
alors l'√©quation r√©siduelle est
$$
R(x;a_{0},a_{1},\dots,a_{N}) = Lu_{N}-f
$$
On cherche donc les coefficients $\{ a_{n} \}$ qui minimisent $|R(x;a_{n})|$ (qui est nulle si $u_{N}$ est exacte.

#example1
On souhaite r√©soudre 
$$
u_{x x}-(x^{6}+3x^{2})u = 0
$$
$$
u(-1)=u(1) = 1
$$
On cherche une solution de la forme polyn√¥miale:
$$u_{2}(x)=1+(1-x^{2})(a_{0}+a_{1}x+a_{2}x^{2})$$
afin de respecter les conditions initiales. On veut calculer les param√®tres $(a_{0},a_{1},a_{2})$ qui minimise la fonction r√©sidu:
$$
\begin{align}
R(x;a_{0},a_{1},a_{2}) &= u_{2x x}-(x^{6}+3x^{2})u_{2} \\ \\
&= (2a_{2}-2a_{0})- 6a_{1}x-(3+3a_{0}+12a_{2})x^{2}-3a_{1}x^{3} +3(a_{0} -a_{2})x^{4}\\ \\
& +3a_{1}x^{5} +(-1-a_{0} +3a_{2})x^{6} -a_{1}x^{7} +(a_{0} -a_{2})x^{8} +a_{1}x^{9} +a_{2}x^{10}
\end{align}
$$


Pour ce faire, on proc√®de par collocation. On choisit 3 points $\{ x_{1},x_{2},x_{3} \}$ (m√™me nombre que de param√®tre/degr√© libert√©) o√π l'on suppose que $u_{2}$ est exacte, c'est √† dire que $R(x_{1})=R(x_{2})=R(x_{3}) =0$. On peut choisir $\{ -0.5,0,0.5 \}$. Cela entraine une syst√®me d'√©quations pour les param√®tres $(a_{0},a_{1},a_{2})$. On trouve que 
$$
\begin{align}
a_{0}=-\frac{764}{3807}, \quad a_{1}=0, \quad a_{2}=-\frac{764}{3807}
\end{align}
$$
Ce qui donne comme fonction d'approximation:
$$
u_{2}(x)=(x^{2}-1)\left( \frac{784x^{2}}{3807}+\frac{784}{3807} \right)+1
$$
On peut comparer avec la vraie solution
$$
\exp\left( \frac{x^{4}-1}{4} \right)
$$
Voici la difference entre les deux:
![Solution exacte (bleu) vs approximation](uexact_vs_u2.png)

et voici l'erreur:
![[erreur1.png]]

# Comparaison entre m√©thode pseudo-spectrales et de diff√©rence (locale)

Pour les m√©thodes de diff√©rences, le domaine est divis√© en intervalles. Les fonctions de bases $\phi _{n}(x)$ sont non nulles  seulement sur un petit nombre de sous intervalles, d'o√π le comportement local. Ainsi, cela produit une matrice de diff√©rentiation qui est dite creuse, qui poss√®de plusieurs avantages computationnels. Cependant, pour approximer les d√©riv√©es, en utilisant les diff√©rences centr√©es, on obtient souvent un ordre de convergence $O(h^{2}),O(h^{4}), O(h^{k})$ d√©pendant du nombre de points qu'on utilise pour l'approximation.

De l'autre cot√©, pour les m√©thodes pseudo-spectrales, si on effectue une collocation √† N points, les N points sont utilis√© pour chaque fonction de bases. Il faudrait parvenir √† une m√©thode de diff√©rence avec un ordre de $O(h^{N})$ pour l'√©quivaloir. Si on double le nombre de points, non seulement, il faudrait parvenir √† $O(h^{2N})$, mais en plus vu que l'espace entre les points $h = O\left( \frac{1}{2N} \right)$, l'ordre de convergence de la m√©thode pseudo-spectrales  est $O\left[\left( \frac{1}{N} \right)^{N}\right]$. C'est pourquoi on dit que les m√©thodes pseudo-spectrales ont une convergence "exponentielle", plus vite que la convergence polynomiale pour tout $N$ fini.